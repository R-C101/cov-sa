{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e739e6251f6d47b792de17be26c901ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9c122944744f64a6192fdddf659ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7ad63d11454e9096e3f37335bf263d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87263f1af23749dda45f674812545525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved CoronaDataset14.csv\n",
      "Processed and saved CoronaDataset28.csv\n",
      "Processed and saved CoronaDataset29.csv\n",
      "Processed and saved CoronaDataset15.csv\n",
      "Processed and saved CoronaDataset17.csv\n",
      "Processed and saved CoronaDataset8.csv\n",
      "Processed and saved CoronaDataset9.csv\n",
      "Processed and saved CoronaDataset16.csv\n",
      "Processed and saved CoronaDataset12.csv\n",
      "Processed and saved CoronaDataset13.csv\n",
      "Processed and saved CoronaDataset39.csv\n",
      "Processed and saved CoronaDataset11.csv\n",
      "Processed and saved CoronaDataset10.csv\n",
      "Processed and saved CoronaDataset38.csv\n",
      "Processed and saved CoronaDataset35.csv\n",
      "Processed and saved CoronaDataset21.csv\n",
      "Processed and saved CoronaDataset2.csv\n",
      "Processed and saved CoronaDataset3.csv\n",
      "Processed and saved CoronaDataset20.csv\n",
      "Processed and saved CoronaDataset34.csv\n",
      "Processed and saved CoronaDataset22.csv\n",
      "Processed and saved CoronaDataset36.csv\n",
      "Processed and saved CoronaDataset1.csv\n",
      "Processed and saved CoronaDataset37.csv\n",
      "Processed and saved CoronaDataset23.csv\n",
      "Processed and saved CoronaDataset27.csv\n",
      "Processed and saved CoronaDataset33.csv\n",
      "Processed and saved CoronaDataset4.csv\n",
      "Processed and saved corona_tweet42.csv\n",
      "Processed and saved coronadataset5.csv\n",
      "Processed and saved CoronaDataset32.csv\n",
      "Processed and saved CoronaDataset26.csv\n",
      "Processed and saved CoronaDataset18.csv\n",
      "Processed and saved CoronaDataset30.csv\n",
      "Processed and saved CoronaDataset24.csv\n",
      "Processed and saved CoronaDataset7.csv\n",
      "Processed and saved corona_tweet41.csv\n",
      "Processed and saved corona_tweet40.csv\n",
      "Processed and saved CoronaDataset6.csv\n",
      "Processed and saved CoronaDataset25.csv\n",
      "Processed and saved CoronaDataset31.csv\n",
      "Processed and saved CoronaDataset19.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "input_folder = \"CoronaTweets\"\n",
    "output_folder = \"results\"\n",
    "\n",
    "# Create the results folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each CSV file in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if 'text' column exists in the file\n",
    "        if 'text' not in df.columns:\n",
    "            print(f\"Skipping {file_name}: 'text' column not found.\")\n",
    "            continue\n",
    "        \n",
    "        # Get the text data from the 'text' column\n",
    "        texts = df['text'].tolist()\n",
    "        \n",
    "        # Perform sentiment analysis\n",
    "        results = sentiment_pipeline(texts)\n",
    "        \n",
    "        # Add the label and score to the dataframe\n",
    "        df['label'] = [result['label'] for result in results]\n",
    "        df['score'] = [result['score'] for result in results]\n",
    "        \n",
    "        # Save the updated dataframe to the results folder\n",
    "        output_file_path = os.path.join(output_folder, file_name)\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        \n",
    "        print(f\"Processed and saved {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved corona_tweet12.csv\n",
      "Processed and saved corona_tweet06.csv\n",
      "Processed and saved corona_tweet07.csv\n",
      "Processed and saved corona_tweet13.csv\n",
      "Processed and saved corona_tweet05.csv\n",
      "Processed and saved corona_tweet11.csv\n",
      "Processed and saved corona_tweet10.csv\n",
      "Processed and saved corona_tweet04.csv\n",
      "Processed and saved corona_tweet28.csv\n",
      "Processed and saved corona_tweet14.csv\n",
      "Processed and saved corona_tweet15.csv\n",
      "Processed and saved corona_tweet01.csv\n",
      "Processed and saved corona_tweet17.csv\n",
      "Processed and saved corona_tweet03.csv\n",
      "Processed and saved corona_tweet02.csv\n",
      "Processed and saved corona_tweet16.csv\n",
      "Processed and saved corona_tweet27.csv\n",
      "Processed and saved corona_tweet26.csv\n",
      "Processed and saved corona_tweet24.csv\n",
      "Processed and saved corona_tweet18.csv\n",
      "Processed and saved corona_tweet19.csv\n",
      "Processed and saved corona_tweet25.csv\n",
      "Processed and saved corona_tweet09.csv\n",
      "Processed and saved corona_tweet21.csv\n",
      "Processed and saved corona_tweet20.csv\n",
      "Processed and saved corona_tweet08.csv\n",
      "Processed and saved corona_tweet22.csv\n",
      "Processed and saved corona_tweet23.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "input_folder = \"CoronaTweets/Second wave\"\n",
    "output_folder = \"results/second_wave\"\n",
    "\n",
    "# Create the results folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each CSV file in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        # Read the CSV file\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if 'text' column exists in the file\n",
    "        if 'text' not in df.columns:\n",
    "            print(f\"Skipping {file_name}: 'text' column not found.\")\n",
    "            continue\n",
    "        \n",
    "        # Get the text data from the 'text' column\n",
    "        texts = df['text'].tolist()\n",
    "        \n",
    "        # Perform sentiment analysis\n",
    "        results = sentiment_pipeline(texts)\n",
    "        \n",
    "        # Add the label and score to the dataframe\n",
    "        df['label'] = [result['label'] for result in results]\n",
    "        df['score'] = [result['score'] for result in results]\n",
    "        \n",
    "        # Save the updated dataframe to the results folder\n",
    "        output_file_path = os.path.join(output_folder, file_name)\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        \n",
    "        print(f\"Processed and saved {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
